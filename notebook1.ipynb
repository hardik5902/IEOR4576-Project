{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b47663",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Avellaneda & Lee (2010)-style statistical arbitrage on S&P 100\n",
    "Using sector ETF factors and Yahoo Finance data.\n",
    "\n",
    "- Universe: S&P 100 stocks (user fills in tickers + sector ETF map)\n",
    "- Factors: Sector ETFs (e.g., XLK, XLF, XLE, etc.)\n",
    "- Data: 2022-01-01 to 2025-12-31 from Yahoo Finance\n",
    "- Backtest: 2025 only\n",
    "- Method:\n",
    "    1. For each stock & date, regress past 60 days of returns on sector ETF returns\n",
    "    2. Compute residuals, rolling mean & std → s-scores\n",
    "    3. Generate mean-reversion signals based on s-scores\n",
    "    4. Build daily dollar-neutral portfolio across stocks\n",
    "    5. Compute performance metrics and plot equity curve\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e163156",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 1. CONFIGURATION\n",
    "# -------------------------------\n",
    "\n",
    "# IMPORTANT: Fill this with your S&P 100 tickers (no spaces, Yahoo symbols)\n",
    "# You can start with a subset while debugging, then expand.\n",
    "SP100_TICKERS = [\n",
    "    \"AAPL\",\"ABBV\",\"ABT\",\"ACN\",\"ADBE\",\"AIG\",\"AMD\",\"AMGN\",\"AMT\",\"AMZN\",\n",
    "    \"AVGO\",\"AXP\",\"BA\",\"BAC\",\"BK\",\"BKNG\",\"BLK\",\"BMY\",\"C\",\n",
    "    \"CAT\",\"CL\",\"CMCSA\",\"COF\",\"COP\",\"COST\",\"CRM\",\"CSCO\",\"CVS\",\"CVX\",\n",
    "    \"DE\",\"DHR\",\"DIS\",\"DUK\",\"EMR\",\"FDX\",\"GD\",\"GE\",\"GILD\",\"GM\",\n",
    "    \"GOOG\",\"GOOGL\",\"GS\",\"HD\",\"HON\",\"IBM\",\"INTC\",\"INTU\",\"ISRG\",\"JNJ\",\n",
    "    \"JPM\",\"KO\",\"LIN\",\"LLY\",\"LMT\",\"LOW\",\"MA\",\"MCD\",\"MDLZ\",\"MDT\",\n",
    "    \"MET\",\"META\",\"MMM\",\"MO\",\"MRK\",\"MS\",\"MSFT\",\"NEE\",\"NFLX\",\"NKE\",\n",
    "    \"NOW\",\"NVDA\",\"ORCL\",\"PEP\",\"PFE\",\"PG\",\"PLTR\",\"PM\",\"PYPL\",\"QCOM\",\n",
    "    \"RTX\",\"SBUX\",\"SCHW\",\"SO\",\"SPG\",\"T\",\"TGT\",\"TMO\",\"TMUS\",\"TSLA\",\n",
    "    \"TXN\",\"UBER\",\"UNH\",\"UNP\",\"UPS\",\"USB\",\"V\",\"VZ\",\"WFC\",\"WMT\",\"XOM\"\n",
    "]\n",
    "\n",
    "\n",
    "# Sector ETFs (SPDR Select Sector funds, for example)\n",
    "SECTOR_ETFS = [\n",
    "    \"XLE\",  # Energy\n",
    "    \"XLF\",  # Financials\n",
    "    \"XLK\",  # Technology\n",
    "    \"XLV\",  # Health Care\n",
    "    \"XLY\",  # Consumer Discretionary\n",
    "    \"XLP\",  # Consumer Staples\n",
    "    \"XLI\",  # Industrials\n",
    "    \"XLB\",  # Materials\n",
    "    \"XLU\",  # Utilities\n",
    "    \"XLC\",  # Communication Services (post-2018)\n",
    "    \"XLRE\", # Real Estate\n",
    "]\n",
    "\n",
    "MARKET_ETF = \"SPY\"  # For optional beta-neutrality vs market\n",
    "\n",
    "# Map each stock to ONE sector ETF (simplest version of A&L ETF-factor model)\n",
    "# !!! You MUST fill this mapping properly for your tickers !!!\n",
    "# Example mapping for a few names:\n",
    "SECTOR_ETF_MAP = {\n",
    "    # Information Technology → XLK\n",
    "    \"AAPL\": \"XLK\",\n",
    "    \"ACN\":  \"XLK\",\n",
    "    \"ADBE\": \"XLK\",\n",
    "    \"AMD\":  \"XLK\",\n",
    "    \"AVGO\": \"XLK\",\n",
    "    \"CRM\":  \"XLK\",\n",
    "    \"CSCO\": \"XLK\",\n",
    "    \"IBM\":  \"XLK\",\n",
    "    \"INTC\": \"XLK\",\n",
    "    \"INTU\": \"XLK\",\n",
    "    \"MSFT\": \"XLK\",\n",
    "    \"NOW\":  \"XLK\",\n",
    "    \"NVDA\": \"XLK\",\n",
    "    \"ORCL\": \"XLK\",\n",
    "    \"PLTR\": \"XLK\",\n",
    "    \"QCOM\": \"XLK\",\n",
    "    \"TXN\":  \"XLK\",\n",
    "\n",
    "    # Health Care → XLV\n",
    "    \"ABBV\": \"XLV\",\n",
    "    \"ABT\":  \"XLV\",\n",
    "    \"AMGN\": \"XLV\",\n",
    "    \"CVS\":  \"XLV\",\n",
    "    \"DHR\":  \"XLV\",\n",
    "    \"GILD\": \"XLV\",\n",
    "    \"ISRG\": \"XLV\",\n",
    "    \"JNJ\":  \"XLV\",\n",
    "    \"LLY\":  \"XLV\",\n",
    "    \"MDT\":  \"XLV\",\n",
    "    \"MRK\":  \"XLV\",\n",
    "    \"PFE\":  \"XLV\",\n",
    "    \"TMO\":  \"XLV\",\n",
    "    \"UNH\":  \"XLV\",\n",
    "\n",
    "    # Financials → XLF\n",
    "    \"AIG\":  \"XLF\",\n",
    "    \"AXP\":  \"XLF\",\n",
    "    \"BAC\":  \"XLF\",\n",
    "    \"BK\":   \"XLF\",\n",
    "    \"BLK\":  \"XLF\",\n",
    "    \"C\":    \"XLF\",\n",
    "    \"COF\":  \"XLF\",\n",
    "    \"GS\":   \"XLF\",\n",
    "    \"JPM\":  \"XLF\",\n",
    "    \"MA\":   \"XLF\",\n",
    "    \"MET\":  \"XLF\",\n",
    "    \"MS\":   \"XLF\",\n",
    "    \"PYPL\": \"XLF\",\n",
    "    \"SCHW\": \"XLF\",\n",
    "    \"USB\":  \"XLF\",\n",
    "    \"V\":    \"XLF\",\n",
    "    \"WFC\":  \"XLF\",\n",
    "\n",
    "    # Real Estate → XLRE\n",
    "    \"AMT\": \"XLRE\",\n",
    "    \"SPG\": \"XLRE\",\n",
    "\n",
    "    # Consumer Discretionary → XLY\n",
    "    \"AMZN\": \"XLY\",\n",
    "    \"BKNG\": \"XLY\",\n",
    "    \"GM\":   \"XLY\",\n",
    "    \"HD\":   \"XLY\",\n",
    "    \"LOW\":  \"XLY\",\n",
    "    \"MCD\":  \"XLY\",\n",
    "    \"NKE\":  \"XLY\",\n",
    "    \"SBUX\": \"XLY\",\n",
    "    \"TGT\":  \"XLY\",\n",
    "    \"TSLA\": \"XLY\",\n",
    "\n",
    "    # Consumer Staples → XLP\n",
    "    \"CL\":   \"XLP\",\n",
    "    \"COST\": \"XLP\",\n",
    "    \"KO\":   \"XLP\",\n",
    "    \"MDLZ\": \"XLP\",\n",
    "    \"MO\":   \"XLP\",\n",
    "    \"PEP\":  \"XLP\",\n",
    "    \"PG\":   \"XLP\",\n",
    "    \"PM\":   \"XLP\",\n",
    "    \"WMT\":  \"XLP\",\n",
    "\n",
    "    # Communication Services → XLC\n",
    "    \"CMCSA\": \"XLC\",\n",
    "    \"DIS\":   \"XLC\",\n",
    "    \"GOOG\":  \"XLC\",\n",
    "    \"GOOGL\": \"XLC\",\n",
    "    \"META\":  \"XLC\",\n",
    "    \"NFLX\":  \"XLC\",\n",
    "    \"T\":     \"XLC\",\n",
    "    \"TMUS\":  \"XLC\",\n",
    "    \"VZ\":    \"XLC\",\n",
    "\n",
    "    # Energy → XLE\n",
    "    \"COP\":  \"XLE\",\n",
    "    \"CVX\":  \"XLE\",\n",
    "    \"XOM\":  \"XLE\",\n",
    "\n",
    "    # Industrials → XLI\n",
    "    \"BA\":   \"XLI\",\n",
    "    \"CAT\":  \"XLI\",\n",
    "    \"DE\":   \"XLI\",\n",
    "    \"EMR\":  \"XLI\",\n",
    "    \"FDX\":  \"XLI\",\n",
    "    \"GD\":   \"XLI\",\n",
    "    \"GE\":   \"XLI\",\n",
    "    \"HON\":  \"XLI\",\n",
    "    \"LMT\":  \"XLI\",\n",
    "    \"RTX\":  \"XLI\",\n",
    "    \"UBER\": \"XLI\",   # per your table, Industrials\n",
    "    \"UNP\":  \"XLI\",\n",
    "    \"UPS\":  \"XLI\",\n",
    "\n",
    "    # Materials → XLB\n",
    "    \"LIN\":  \"XLB\",\n",
    "\n",
    "    # Utilities → XLU\n",
    "    \"DUK\": \"XLU\",\n",
    "    \"NEE\": \"XLU\",\n",
    "    \"SO\":  \"XLU\",\n",
    "}\n",
    "\n",
    "\n",
    "# Sanity check: only keep tickers we have mapped\n",
    "UNIVERSE = [t for t in SP100_TICKERS if t in SECTOR_ETF_MAP]\n",
    "\n",
    "# Backtest & data parameters\n",
    "START_DATE = \"2022-01-01\"\n",
    "END_DATE   = \"2025-12-31\"\n",
    "TRAIN_END  = \"2024-12-31\"  # we will analyze performance in 2025\n",
    "\n",
    "ROLLING_WINDOW = 60  # days for regression and residual stats\n",
    "ENTRY_Z = 1.25\n",
    "EXIT_Z = 0.5\n",
    "TX_COST_PER_UNIT = 0.001  # 10 bps round-trip per unit of turnover (rough)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a8741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for 110 tickers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  110 of 110 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:\n",
      "Stock returns: (977, 98)\n",
      "ETF returns: (977, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 2. DOWNLOAD DATA FROM YAHOO\n",
    "# -------------------------------\n",
    "\n",
    "all_tickers = sorted(set(UNIVERSE + SECTOR_ETFS + [MARKET_ETF]))\n",
    "print(f\"Downloading data for {len(all_tickers)} tickers...\")\n",
    "\n",
    "data = yf.download(\n",
    "    tickers=all_tickers,\n",
    "    start=START_DATE,\n",
    "    end=END_DATE,\n",
    "    auto_adjust=True,\n",
    "    progress=True,\n",
    ")\n",
    "\n",
    "# We'll use Adjusted Close prices; Volume available if you want volume-based tweaks later\n",
    "prices = data[\"Close\"]  # using 'Close' since auto_adjust=True\n",
    "prices = prices.dropna(how=\"all\")\n",
    "\n",
    "# Compute daily log returns\n",
    "returns = np.log(prices / prices.shift(1))\n",
    "returns = returns.dropna(how=\"all\")\n",
    "\n",
    "\n",
    "stock_returns = returns[UNIVERSE]\n",
    "etf_returns   = returns[SECTOR_ETFS].copy()\n",
    "market_returns = returns[[MARKET_ETF]].copy()\n",
    "\n",
    "print(\"Data shapes:\")\n",
    "print(\"Stock returns:\", stock_returns.shape)\n",
    "print(\"ETF returns:\", etf_returns.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bd022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ETF-factor residuals... (this may take a bit)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 3. ROLLING ETF-FACTOR REGRESSION → RESIDUALS\n",
    "# -------------------------------\n",
    "\n",
    "# We will compute residuals only for dates where we have at least ROLLING_WINDOW prior days\n",
    "dates = stock_returns.index\n",
    "test_mask = dates >= TRAIN_END  # this includes TRAIN_END itself; we'll shift later\n",
    "test_dates = dates[dates >= \"2025-01-01\"]  # strict test period in 2025\n",
    "\n",
    "residuals = pd.DataFrame(index=dates, columns=UNIVERSE, dtype=float)\n",
    "\n",
    "print(\"Computing ETF-factor residuals... (this may take a bit)\")\n",
    "\n",
    "for current_idx in range(ROLLING_WINDOW, len(dates)):\n",
    "    date = dates[current_idx]\n",
    "    # 60 prior days window\n",
    "    window_start_idx = current_idx - ROLLING_WINDOW\n",
    "    window_dates = dates[window_start_idx:current_idx]\n",
    "\n",
    "    # For each stock, regress on its sector ETF over the window\n",
    "    for ticker in UNIVERSE:\n",
    "        sector_etf = SECTOR_ETF_MAP[ticker]\n",
    "        y = stock_returns.loc[window_dates, ticker].values\n",
    "        x = etf_returns.loc[window_dates, sector_etf].values\n",
    "\n",
    "        # Simple OLS: y = alpha + beta * x\n",
    "        if np.isnan(y).any() or np.isnan(x).any():\n",
    "            residuals.loc[date, ticker] = np.nan\n",
    "            continue\n",
    "\n",
    "        x_mean = x.mean()\n",
    "        y_mean = y.mean()\n",
    "        cov_xy = np.mean((x - x_mean) * (y - y_mean))\n",
    "        var_x = np.mean((x - x_mean) ** 2)\n",
    "        if var_x == 0:\n",
    "            residuals.loc[date, ticker] = np.nan\n",
    "            continue\n",
    "\n",
    "        beta = cov_xy / var_x\n",
    "        alpha = y_mean - beta * x_mean\n",
    "\n",
    "        # Residual at \"date\"\n",
    "        y_t = stock_returns.loc[date, ticker]\n",
    "        x_t = etf_returns.loc[date, sector_etf]\n",
    "        eps_t = y_t - (alpha + beta * x_t)\n",
    "        residuals.loc[date, ticker] = eps_t\n",
    "\n",
    "print(\"Residuals computed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d0e410c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-scores shape: (0, 99)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 4. COMPUTE S-SCORES (Z-SCORES) FROM RESIDUALS\n",
    "# -------------------------------\n",
    "\n",
    "# Rolling mean & std of residuals to approximate equilibrium\n",
    "mu_resid = residuals.rolling(window=ROLLING_WINDOW, min_periods=20).mean()\n",
    "sigma_resid = residuals.rolling(window=ROLLING_WINDOW, min_periods=20).std()\n",
    "\n",
    "s_scores = (residuals - mu_resid) / sigma_resid\n",
    "\n",
    "# We'll only trade when we have s-scores defined and we're in 2025\n",
    "s_scores_test = s_scores.loc[test_dates]\n",
    "\n",
    "print(\"S-scores shape:\", s_scores_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a103a88",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "iloc cannot enlarge its target object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 5. GENERATE MEAN-REVERSION POSITIONS (ITERATIVE)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[1;32m      5\u001b[0m positions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(index\u001b[38;5;241m=\u001b[39mtest_dates, columns\u001b[38;5;241m=\u001b[39mUNIVERSE, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mpositions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# start flat\u001b[39;00m\n\u001b[1;32m      8\u001b[0m sorted_test_dates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(test_dates)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, date \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sorted_test_dates):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexing.py:908\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    906\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m    907\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_setitem_indexer(key)\n\u001b[0;32m--> 908\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_valid_setitem_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m    911\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexing.py:1646\u001b[0m, in \u001b[0;36m_iLocIndexer._has_valid_setitem_indexer\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer(i):\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ax):\n\u001b[0;32m-> 1646\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc cannot enlarge its target object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   1648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc cannot enlarge its target object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: iloc cannot enlarge its target object"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 5. GENERATE MEAN-REVERSION POSITIONS (ITERATIVE)\n",
    "# -------------------------------\n",
    "\n",
    "positions = pd.DataFrame(index=test_dates, columns=UNIVERSE, dtype=float)\n",
    "positions.iloc[0] = 0.0  # start flat\n",
    "\n",
    "sorted_test_dates = list(test_dates)\n",
    "\n",
    "for i, date in enumerate(sorted_test_dates):\n",
    "    if i == 0:\n",
    "        prev_pos = positions.iloc[0].copy()\n",
    "    else:\n",
    "        prev_date = sorted_test_dates[i - 1]\n",
    "        prev_pos = positions.loc[prev_date].copy()\n",
    "\n",
    "    current_pos = prev_pos.copy()\n",
    "\n",
    "    for ticker in UNIVERSE:\n",
    "        s = s_scores.loc[date, ticker]\n",
    "        if np.isnan(s):\n",
    "            # keep previous position if no signal information\n",
    "            continue\n",
    "\n",
    "        # Entry rules\n",
    "        if s < -ENTRY_Z:\n",
    "            current_pos[ticker] = 1.0  # long\n",
    "        elif s > ENTRY_Z:\n",
    "            current_pos[ticker] = -1.0  # short\n",
    "        # Exit rule\n",
    "        elif abs(s) < EXIT_Z:\n",
    "            current_pos[ticker] = 0.0   # exit\n",
    "\n",
    "    positions.loc[date] = current_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c914e4a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_test_dates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 6. NORMALIZE POSITIONS → DOLLAR-NEUTRAL WEIGHTS\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[1;32m      5\u001b[0m weights \u001b[38;5;241m=\u001b[39m positions\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m \u001b[43msorted_test_dates\u001b[49m:\n\u001b[1;32m      8\u001b[0m     pos \u001b[38;5;241m=\u001b[39m positions\u001b[38;5;241m.\u001b[39mloc[date]\n\u001b[1;32m      9\u001b[0m     long_mask \u001b[38;5;241m=\u001b[39m pos \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_test_dates' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 6. NORMALIZE POSITIONS → DOLLAR-NEUTRAL WEIGHTS\n",
    "# -------------------------------\n",
    "\n",
    "weights = positions.copy()\n",
    "\n",
    "for date in sorted_test_dates:\n",
    "    pos = positions.loc[date]\n",
    "    long_mask = pos > 0\n",
    "    short_mask = pos < 0\n",
    "\n",
    "    n_long = long_mask.sum()\n",
    "    n_short = short_mask.sum()\n",
    "\n",
    "    w = pd.Series(0.0, index=UNIVERSE)\n",
    "\n",
    "    if n_long > 0:\n",
    "        w_long = 0.5 / n_long  # 50% long side\n",
    "        w[long_mask] = w_long\n",
    "    if n_short > 0:\n",
    "        w_short = -0.5 / n_short  # 50% short side\n",
    "        w[short_mask] = w_short\n",
    "\n",
    "    weights.loc[date] = w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe69699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 7. DAILY P&L WITH TRANSACTION COSTS\n",
    "# -------------------------------\n",
    "\n",
    "strategy_returns = pd.Series(index=test_dates, dtype=float)\n",
    "prev_w = pd.Series(0.0, index=UNIVERSE)\n",
    "\n",
    "for date in sorted_test_dates:\n",
    "    w = weights.loc[date]\n",
    "    # Raw return from stock legs\n",
    "    r_stock = stock_returns.loc[date, UNIVERSE]\n",
    "    daily_ret_before_costs = np.nansum(w * r_stock)\n",
    "\n",
    "    # Turnover & transaction costs\n",
    "    turnover = np.nansum(np.abs(w - prev_w))  # L1 change in weights\n",
    "    # Rough: cost proportional to turnover\n",
    "    cost = TX_COST_PER_UNIT * turnover\n",
    "\n",
    "    strategy_returns.loc[date] = daily_ret_before_costs - cost\n",
    "\n",
    "    prev_w = w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b8f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 8. PERFORMANCE METRICS\n",
    "# -------------------------------\n",
    "\n",
    "def annualized_sharpe(returns_series, periods_per_year=252):\n",
    "    mu = returns_series.mean()\n",
    "    sigma = returns_series.std()\n",
    "    if sigma == 0 or np.isnan(sigma):\n",
    "        return np.nan\n",
    "    return np.sqrt(periods_per_year) * mu / sigma\n",
    "\n",
    "def max_drawdown(equity_curve):\n",
    "    cum_max = equity_curve.cummax()\n",
    "    dd = (equity_curve - cum_max) / cum_max\n",
    "    return dd.min()\n",
    "\n",
    "equity = (1 + strategy_returns).cumprod()\n",
    "sr = annualized_sharpe(strategy_returns)\n",
    "mdd = max_drawdown(equity)\n",
    "\n",
    "print(\"\\n=== Backtest Results (2025) ===\")\n",
    "print(f\"Annualized Sharpe Ratio: {sr:.3f}\")\n",
    "print(f\"Total Return: {equity.iloc[-1] - 1:.2%}\")\n",
    "print(f\"Max Drawdown: {mdd:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 9. PLOT EQUITY CURVE\n",
    "# -------------------------------\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(equity.index, equity.values, label=\"Stat-Arb Strategy\")\n",
    "plt.axhline(1.0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "plt.title(\"Statistical Arbitrage Strategy on S&P 100 (ETF-factor, 2025)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Equity (starting at 1.0)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
